"""Trajectory-level metrics for autoregressive LLM analysis.

"Trajectory" = a sequence of tokens generated by an LLM, with their logprobs.
This is a sequence of decisions, not a single distribution.

Input: logprobs = [ℓ₁, …, ℓₘ] where ℓᵢ = log P(wᵢ | w<ᵢ)
       Each ℓᵢ ≤ 0. The list is NOT a distribution.

These metrics wrap entropy_diversity primitives, interpreting them
in the context of sequential token generation.
"""

from __future__ import annotations

from typing import Sequence

from .math_primitives import argmin, argmax
from .entropy_diversity import _EPS, surprise, rarity, power_mean_from_logprobs


# ── Pointwise (per-token) metrics ────────────────────────────────────────────


def surprise_trajectory(logprobs: Sequence[float]) -> list[float]:
    """Surprise at every position along a trajectory."""
    return [surprise(lp) for lp in logprobs]


def rarity_trajectory(logprobs: Sequence[float]) -> list[float]:
    """Rarity at every position along a trajectory."""
    return [rarity(lp) for lp in logprobs]


# ── Generalized trajectory metrics (order α) — most general ──────────────────


def alpha_inv_perplexity(logprobs: Sequence[float], alpha: float) -> float:
    """Generalized inverse-perplexity of order α.

    Wraps power_mean_from_logprobs: M_α(p) where p = exp(logprobs).

    Power mean of order α applied to token probabilities:
        α → −∞: min pᵢ  (worst-case token)
        α = -1: harmonic mean (pessimistic — emphasizes hard tokens)
        α = 0:  geometric mean (standard inv-perplexity)
        α = 1:  arithmetic mean (optimistic — tolerates hard tokens)
        α → +∞: max pᵢ  (best-case token)

    Range: (0, 1]. Higher = better. Monotonic in α.
    """
    return power_mean_from_logprobs(logprobs, alpha)


def alpha_perplexity(logprobs: Sequence[float], alpha: float) -> float:
    """Generalized perplexity of order α. PP_α = 1 / M_α(p).

    Range: [1, ∞). Lower = better.
    """
    inv = alpha_inv_perplexity(logprobs, alpha)
    return 1.0 / inv if inv > _EPS else float("inf")


# ── Standard metrics (α=0 special cases, geometric mean) ─────────────────────


def inv_perplexity(logprobs: Sequence[float]) -> float:
    """Geometric mean token probability (= alpha_inv_perplexity with α=0).

    PP⁻¹ = exp(mean(logprobs)) = (∏ pᵢ)^{1/m}

    Range: (0, 1]. Higher = better.
    """
    return alpha_inv_perplexity(logprobs, alpha=0.0)


def perplexity(logprobs: Sequence[float]) -> float:
    """Effective vocabulary size per token (= alpha_perplexity with α=0).

    PP = exp(-mean(logprobs)) = (∏ pᵢ)^{−1/m}

    Range: [1, ∞). Lower = better.
    Interpretation: "model is as uncertain as choosing uniformly among PP tokens."
    """
    return alpha_perplexity(logprobs, alpha=0.0)


def empirical_cross_entropy(logprobs: Sequence[float]) -> float:
    """Average surprise per token (empirical cross-entropy).

    H = −(1/m) Σ ℓᵢ = mean(surprise)

    Range: [0, ∞). Lower = better.
    """
    if not logprobs:
        return float("inf")
    return sum(surprise(lp) for lp in logprobs) / len(logprobs)


# ── Logprob sums ─────────────────────────────────────────────────────────────


def total_logprob(logprobs: Sequence[float]) -> float:
    """Total log-probability of the whole response.

    log P(response) = Σ ℓᵢ

    Range: (−∞, 0]. Higher = better. Length-dependent.
    """
    return sum(logprobs)


def partial_logprob(logprobs: Sequence[float], start: int, end: int) -> float:
    """Log-probability of just the label tokens.

    log P(label) = Σ ℓᵢ for i ∈ [start, end)
    """
    return sum(logprobs[start:end])


def worst_token_logprob(logprobs: Sequence[float]) -> float:
    """Log-prob of the hardest token. min(ℓᵢ). Higher = better."""
    return min(logprobs) if logprobs else 0.0


def worst_token_position(logprobs: Sequence[float]) -> int:
    """Position of the hardest token. argmin(ℓᵢ)."""
    return argmin(list(logprobs))


def best_token_logprob(logprobs: Sequence[float]) -> float:
    """Log-prob of the easiest token. max(ℓᵢ)."""
    return max(logprobs) if logprobs else 0.0


def best_token_position(logprobs: Sequence[float]) -> int:
    """Position of the easiest token. argmax(ℓᵢ)."""
    return argmax(list(logprobs))


# ── Rank-based metrics (require full logits) ─────────────────────────────────


def token_ranks_from_logits(
    token_ids: Sequence[int],
    full_logits,  # torch.Tensor [n_sequence, vocab_size]
) -> list[int]:
    """Compute rank of each chosen token in the vocab distribution.

    Rank 1 = highest probability token (greedy choice).
    Higher rank = more surprising choice.

    Args:
        token_ids: [n_sequence] chosen token IDs
        full_logits: [n_sequence, vocab_size] logits at each position

    Returns:
        [n_sequence] ranks (1-indexed, where 1 = top token)
    """
    import torch

    if full_logits is None:
        return [1] * len(token_ids)

    ranks = []
    for pos, token_id in enumerate(token_ids):
        if pos >= full_logits.shape[0]:
            ranks.append(1)
            continue

        logits_at_pos = full_logits[pos]
        # Count how many tokens have higher logits than the chosen one
        chosen_logit = logits_at_pos[token_id].item()
        rank = (logits_at_pos > chosen_logit).sum().item() + 1
        ranks.append(int(rank))

    return ranks


def worst_token_rank(ranks: Sequence[int]) -> int:
    """Rank of the worst-ranked token. Higher = more surprising choice somewhere."""
    return max(ranks) if ranks else 1


def worst_rank_position(ranks: Sequence[int]) -> int:
    """Position of the worst-ranked token."""
    return argmax(list(ranks))


# ── Top-p normalized metrics ─────────────────────────────────────────────────


def top_p_normalized_logprobs(
    token_ids: Sequence[int],
    full_logits,  # torch.Tensor [n_sequence, vocab_size]
    p: int = 100,
) -> list[float]:
    """Compute logprobs normalized to top-p tokens at each position.

    For each position:
    1. Take top-p tokens by probability
    2. Renormalize their probabilities to sum to 1
    3. Return the normalized logprob of the chosen token

    This gives higher probabilities since we're only considering
    plausible alternatives, not the entire vocabulary.

    Args:
        token_ids: [n_sequence] chosen token IDs
        full_logits: [n_sequence, vocab_size] logits at each position
        p: Number of top tokens to consider (default 100)

    Returns:
        [n_sequence] normalized logprobs
    """
    import torch
    import torch.nn.functional as F

    if full_logits is None:
        return [0.0] * len(token_ids)

    normalized_logprobs = []
    for pos, token_id in enumerate(token_ids):
        if pos >= full_logits.shape[0]:
            normalized_logprobs.append(0.0)
            continue

        logits_at_pos = full_logits[pos]

        # Get top-p logits and indices
        top_logits, top_indices = torch.topk(
            logits_at_pos, min(p, logits_at_pos.shape[0])
        )

        # Check if chosen token is in top-p
        token_in_top_p = (top_indices == token_id).any()

        if token_in_top_p:
            # Normalize top-p to get probabilities
            top_probs = F.softmax(top_logits, dim=0)
            # Find position of chosen token in top-p
            token_pos_in_top = (
                (top_indices == token_id).nonzero(as_tuple=True)[0].item()
            )
            normalized_logprobs.append(torch.log(top_probs[token_pos_in_top]).item())
        else:
            # Token not in top-p, assign very low probability
            normalized_logprobs.append(float("-inf"))

    return normalized_logprobs
